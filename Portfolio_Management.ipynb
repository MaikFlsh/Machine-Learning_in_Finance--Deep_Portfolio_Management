{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Management \n",
    "\n",
    "\n",
    "## Optimierungsproblem\n",
    "## Mögliche Ziele: erwartete Rendite maximieren oder Risiko reduzieren\n",
    "\n",
    "Verwendete Methoden: \n",
    "- Autoencoder\n",
    "- Riskoaufteilung mit hierarchischem Clustering\n",
    "- Prognosebasiertes Portfolio\n",
    "\n",
    "\n",
    "Benchmark für den Vergleich der verwendenten Methoden:\n",
    "- Gleichgewichtetes Portfolio dh. jede Aktie besitzt den gleichen Anteil am Gesamtportfolio\n",
    "\n",
    "\n",
    "#### Grundlagen\n",
    "\n",
    "- Portfoliorendite: $R_{PF} = w^{t} r $  , wobei $w $ Vektor mit den einzelnen Gewichten der Aktien und $ \\sum_{i}^{n} w_i = 1  $\n",
    "- Portfoliovarianz: $V_{PF} = w^{t} \\Sigma w $ , wobei $\\Sigma $ die Varianzkovarianzmatrix ist \n",
    "- Sharpe-Ratio: $SR_{PF} = \\frac{R_{PF}-R_{riskolos}}{\\sqrt{V_{PF}}}$ , wobei $R_{riskolos} =0 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pylab as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Aktiendaten\n",
    "\n",
    "\n",
    "\n",
    "#### Folgende Aktien werden im Zeitraum vom 02.01.2018 bis 31.02.2020 betrachtet:\n",
    "\n",
    "- SAP\n",
    "- Siemens\n",
    "- Bayer\n",
    "- BASF\n",
    "- Alianz\n",
    "- Daimler\n",
    "- Deutsche Telekom\n",
    "- Adidas\n",
    "- BMW \n",
    "- Volkswagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Environment\n",
    "from utils import *\n",
    "env = Environment()\n",
    "\n",
    "data = env.load_data()\n",
    "data.plot(figsize=(20,12))\n",
    "plt.ylabel('Aktienpreis in Euro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grundlegende Vereinbarungen\n",
    "N_ASSETS = 10 # Anzahl der Aktien \n",
    "WINDOW_FIT = 125 # Trainingszeitraum in Tagen, entspricht ~ 6 Monaten\n",
    "WINDOW_HOLD = 125 # Haltezeitraum in Tagen \n",
    "env = Environment() # Import der Klasse Environment zum der Einlesen der Daten, sowie Bestimmung der Aktien-, Portfoliorendite etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder \n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"Autoencoder_Netz.png\" width=\"350\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "- Ziel der Autoencoder: Dimensionsreduzierung der ursprünglichen Daten\n",
    "- $f:X \\rightarrow F $ Encoderfunktion , $ f(x_i) = w_1 x_{i} +b_1$ falls linear, hier $f(x_i) = max(0,x_i)$\n",
    "- $g:F \\rightarrow X $ Decoderfunktion , $ g(x_i) = w_2 x_{i} +b_2$\n",
    "- $ | x_i - ( g \\circ f ) (x_i) | \\rightarrow min \\Leftrightarrow | x_i - w_2( max(0,x_i))+b_2 | \\rightarrow min $ \n",
    "- Mittels Kleinste-Quadrate- Methode:  $\\quad$\n",
    "$ \\sum (x_i - w_2( w_1 x_{i} +b_1 )+b_2)^2  \\rightarrow min $ für die Parameter $w_1, w_2, b_1, b_2 $\n",
    "- \"Lernen\" des Netzes mit Backpropagnition Algorithmus \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import AutoencoderAgent # Laden der verwendeten Functionen aus der Klasse AutoencoderAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_ae = AutoencoderAgent(N_ASSETS, allow_short=True, encoding_dim = 5) # Dimensionsreduzierung auf 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_equal, actions_ae = [], []\n",
    "result_equal, result_ae = [], []\n",
    "\n",
    "for i in range(WINDOW_FIT, len(env.data), WINDOW_HOLD): #Start , Stop, Schritt \n",
    "    \n",
    "    # Trainingszeitraum\n",
    "    state = env.get_state(i, WINDOW_FIT, is_cov_matrix=False, is_raw_time_series=True) # Daten für Trainingszeitraum \n",
    "    action_equal = np.ones(N_ASSETS) / N_ASSETS  # Benchmark  der gleichgewichteten Aktien\n",
    "    action_ae = agent_ae.act(state)  # Gewichte der Aktien mittels Autoencoder\n",
    "    \n",
    "    \n",
    "    # Realisierung der Rendite der Methode \n",
    "    state_action = env.get_state(i+WINDOW_HOLD, WINDOW_HOLD, is_cov_matrix=False) #Renditen Haltezeitraums \n",
    "    r = np.dot(state_action, action_equal) # Portfoliorendite gleichgewichtetes Portfolio\n",
    "    result_equal.append(r.tolist())\n",
    "    actions_equal.append(action_equal) # Aufbau Liste Renditen\n",
    "    \n",
    "    r = np.dot(state_action, action_ae) # Portfoliorendite Autoencoder Portfolio\n",
    "    result_ae.append(r.tolist())\n",
    "    actions_ae.append(action_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_equal_vis = [item for sublist in result_equal for item in sublist]\n",
    "result_ae_vis = [item for sublist in result_ae for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renditeverlauf des Gesamtportfolios\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.array(result_equal_vis).cumsum(),label='Benchmark', color = 'black')  \n",
    "plt.plot(np.array(result_ae_vis).cumsum(),label='Autoencoder', color = 'red') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Methode' ,'Rendite','Volatilität','Sharpe-Ratio','alpha', 'beta' )\n",
    "print('EQUAL', print_stats(result_equal_vis, result_equal_vis))\n",
    "print('AUTOENCODER', print_stats(result_ae_vis, result_equal_vis))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_equal, \n",
    "             result_ae, \n",
    "             actions_ae, \n",
    "             N_ASSETS,\n",
    "             state.columns, \n",
    "             'Autoencoder portfolio', './images/ae/', 'series')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riskoaufteilung mit hierarchischem Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Methode basiert auf der Allokation von Risiko\n",
    "- Kovarianzmatrix kann als vollständiger Graph gesehen werden\n",
    "- Zunächst keine hierarchische Struktur in der Kovarianzmatrix vorhanden\n",
    "- Clusterbildung anhand der Kovarianzmatrix\n",
    "- Risiko kann anhand des Clusters rekursiv umverteilt werden\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"HRP_Abbildung.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "### Schritte des Algorithmus zur Erzeugung der hierarchischen Struktur:\n",
    "1. Cluster erstellen  \n",
    "1. Quasi Diagonalisierung\n",
    "1. Rekursive Bisektion\n",
    "\n",
    "wobei in den Schritten 1-3 jeweils einzelne Algorithmen angewendet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import HRPAgent\n",
    "agent_hrp = HRPAgent(N_ASSETS, allow_short=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_equal, actions_hrp = [], []\n",
    "result_equal, result_hrp = [], []\n",
    "\n",
    "for i in range(WINDOW_FIT, len(env.data), WINDOW_HOLD):\n",
    "    # Trainingszeitraum\n",
    "    state = env.get_state(i, WINDOW_FIT, is_cov_matrix=False)# Daten für Trainingszeitraum \n",
    "    action_equal = np.ones(N_ASSETS) / N_ASSETS # Benchmark  der gleichgewichteten Aktien\n",
    "    action_hrp = agent_hrp.act(state) # Gewi3chte der Aktien mittels Autoencoder\n",
    "\n",
    "    # Realisierung der Rendite der Methode \n",
    "    state_action = env.get_state(i+WINDOW_HOLD, WINDOW_HOLD, is_cov_matrix=False) # Renditen Haltezeitraums \n",
    "    \n",
    "    r = np.dot(state_action, action_equal) # Portfoliorendite gleichgewichtetes Portfolio\n",
    "    result_equal.append(r.tolist())\n",
    "    actions_equal.append(action_equal)\n",
    "    \n",
    "    r = np.dot(state_action, action_hrp) # Portfoliorendite hierarchisches Clustering \n",
    "    result_hrp.append(r.tolist())\n",
    "    actions_hrp.append(action_hrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_equal_vis = [item for sublist in result_equal for item in sublist]\n",
    "result_hrp_vis = [item for sublist in result_hrp for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renditeverlauf des Gesamtportfolios\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.array(result_equal_vis).cumsum(),label='Benchmark', color = 'black')  \n",
    "plt.plot(np.array(result_hrp_vis).cumsum(),label='Autoencoder', color = 'red') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Portfolio' ,'Rendite','Volatilität','Sharpe-Ratio','alpha', 'beta' )\n",
    "print('EQUAL HRP', print_stats(result_equal_vis, result_equal_vis))\n",
    "print('HRP', print_stats(result_hrp_vis, result_equal_vis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_equal, \n",
    "             result_hrp, \n",
    "             actions_hrp, \n",
    "             N_ASSETS,\n",
    "             state.columns, \n",
    "             'HRP portfolio', './images/hrp/', 'series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prognosebasiertes Portfolio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Idee:\n",
    "Wenn ein Modell zur Prognose der zukünftigen Aktienpreise exisitiert, können anhand der prognostizierten Preise entsprechende Gewichte verteilt werden, um die Rendite zu erhöhen oder das Risiko zu minimieren.\n",
    "\n",
    "### Exponentielles Glätten\n",
    "- $\\hat{R_{t}} = \\alpha \\cdot R_{{t}}+(1-\\alpha )\\cdot \\hat{R_{{t-1}}}  $ wobei $\\alpha \\in [0,1] $  - Glättungsfaktor und $\\hat{R_{t}}$ die geschätzte Rendite \n",
    "- Glättungsfaktor $\\alpha $ , wobei \n",
    "   - für $ \\alpha =1 $ entspricht der Vorhersagewert dem Messwert  ( keine Glättung ) \n",
    "   - für $ \\alpha =0 $ horizontale Glättung der Zeitreihe ( neuer Vorhersagewert entspricht dem alten Wert) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import SmoothingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_smooth = SmoothingAgent(N_ASSETS, allow_short=True, forecast_horizon = WINDOW_HOLD) # Prognosezeitraum = Haltedauer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_equal, actions_smooth = [], []\n",
    "result_equal, result_smooth = [], []\n",
    "\n",
    "for i in range(WINDOW_FIT, len(env.data), WINDOW_HOLD):\n",
    "    # Trainingszeitraum\n",
    "    state = env.get_state(i, WINDOW_FIT, is_cov_matrix=False, is_raw_time_series=True)# Daten für Trainingszeitraum \n",
    "    action_equal = np.ones(N_ASSETS) / N_ASSETS # Benchmark  der gleichgewichteten Aktien\n",
    "    action_smooth = agent_smooth.act(state) # Gewichte der Aktien mittels exp. Glätten\n",
    "\n",
    "    # Realisierung der Rendite der Methode \n",
    "    state_action = env.get_state(i+WINDOW_HOLD, WINDOW_HOLD, is_cov_matrix=False)\n",
    "    \n",
    "    r = np.dot(state_action, action_equal) # Portfoliorendite gleichgewichtetes Portfolio\n",
    "    result_equal.append(r.tolist())\n",
    "    actions_equal.append(action_equal)\n",
    "    \n",
    "    r = np.dot(state_action, action_smooth) # Portfoliorendite - Prognose exponentielle Glättung\n",
    "    result_smooth.append(r.tolist())\n",
    "    actions_smooth.append(action_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_equal_vis = [item for sublist in result_equal for item in sublist]\n",
    "result_smooth_vis = [item for sublist in result_smooth for item in sublist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renditeverlauf des Gesamtportfolios\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.array(result_equal_vis).cumsum(),label='Benchmark', color = 'black')  \n",
    "plt.plot(np.array(result_smooth_vis).cumsum(),label='exp. Glätten', color = 'red') \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Portfolio' ,'Rendite','Volatilität','Sharpe-Ratio','alpha', 'beta' )\n",
    "print('EQUAL', print_stats(result_equal_vis, result_equal_vis))\n",
    "print('SMOOTHING', print_stats(result_smooth_vis, result_equal_vis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_equal, \n",
    "             result_smooth, \n",
    "             actions_smooth,\n",
    "             N_ASSETS,\n",
    "             state.columns, \n",
    "             'Exp. Glätten ', './images/smoothing/', 'series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit:\n",
    "\n",
    "\n",
    "\n",
    "### Überblick über die Kennzahlen der einzelnen Methoden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renditeverlauf des Gesamtportfolios \n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(np.array(result_equal_vis).cumsum(),color = 'black', label = 'Benchmark') \n",
    "plt.plot(np.array(result_ae_vis).cumsum(),color = 'red', label = 'Autoencoder')\n",
    "plt.plot(np.array(result_hrp_vis).cumsum(),color = 'blue', label = 'HRP') \n",
    "plt.plot(np.array(result_smooth_vis).cumsum(),color = 'green', label = 'Exp. Glätten') \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Portfolio' ,'Rendite','Volatilität','Sharpe-Ratio','alpha', 'beta' )\n",
    "print('EQUAL', print_stats(result_equal_vis, result_equal_vis))\n",
    "print('AUTOENCODER', print_stats(result_ae_vis, result_equal_vis))\n",
    "print('HRP', print_stats(result_hrp_vis, result_equal_vis))\n",
    "print('SMOOTHING', print_stats(result_smooth_vis, result_equal_vis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Überblick 60 Tage Trainings-, sowie Haltedauer \n",
    "Portfolio Rendite Volatilität Sharpe-Ratio alpha beta\n",
    "- EQUAL [0.0002, 0.01, 0.3514, -0.0, 1.0]\n",
    "- AUTOENCODER [0.0003, 0.0104, 0.4775, 0.0001, 1.0113]\n",
    "- HRP [0.0002, 0.0088, 0.4238, 0.0, 0.8501]\n",
    "- SMOOTHING [-0.0005, 0.0099, -0.8464, -0.0005, 0.0391]\n",
    "\n",
    "<div>\n",
    "<img src=\"Überblick_Methoden_60Tage.png\" width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "- Autoencoder, HRP schneiden am besten ab, wobei HRP den Hauptanteil des Portfolios in die Telekom Aktie umschichtet\n",
    "- Kennzahlen der Methoden ziemlich nah an der Benchmark bis auf exp. Glätten\n",
    "\n",
    "\n",
    "#### Überblick 20 Tage Trainings-, sowie Haltedauer \n",
    "\n",
    "Portfolio Rendite Volatilität Sharpe-Ratio alpha beta\n",
    "- EQUAL [0.0002, 0.01, 0.2502, -0.0, 1.0]\n",
    "- AUTOENCODER [0.0003, 0.0103, 0.3942, 0.0001, 1.0015]\n",
    "- HRP [0.0002, 0.0089, 0.2687, 0.0, 0.8495]\n",
    "- SMOOTHING [-0.0001, 0.0088, -0.1249, -0.0, -0.1337]\n",
    "\n",
    "<div>\n",
    "<img src=\"Überblick_Methoden_20Tage.png\" width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "- Autoencoder schneidet am besten ab \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit:\n",
    "\n",
    "\n",
    "\n",
    "- Betrachtung der Kennzahlen (Sharpe-Ratio) : Autoencoder und Riskoaufteilung mit hierarchischem Clustering schneiden am besten ab  \n",
    "- Ausblick: Performance der Methoden mit weiteren Datensätzen bzw. Betrachtung der Daten über einen längeren Zeitraum \n",
    "\n",
    "- Kritisch zu bemerken: Die Gewichtung einzelner Aktien im Portfolio ist teilweise sehr hoch, dadurch entsteht ein konzentriertes Risiko\n",
    "\n",
    "- Trainingszeitraum, Haltedauer und Prognosehorizont (exp. Glätten) besitzen einen Einfluss auf die Kennzahlen,\n",
    "wobei je kürzer der Anlagezeitraum ist, umso mehr Rauschen ist in den Daten\n",
    "- Autoencoder: Welche Dimensionsreduzierung ist sinnhaft, sodass der Prognosefehler minimal  und der Rechenaufwand überschaubar bleibt ? \n",
    "- Schlechte Performance des prognosebasiertes Portfolio : Zu simples Modell zur Prognose verwendet, die Vewendung eines stochastisches Volatilitätsmodell (bspw. Garch ) ist zu empfehlen\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
